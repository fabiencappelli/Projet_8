{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tPtBpZewuvbcwktkHhoeBK16gEqw6dVB","timestamp":1750407212029},{"file_id":"1id2SLSUjyP3NMFd7Cx1XsDYQXl-Sj45e","timestamp":1750366658490}],"gpuType":"A100","machine_shape":"hm","mount_file_id":"154uxaD-AYDNhj-jG5J3HUCFlNfhtKxLm","authorship_tag":"ABX9TyOcAAQlUnS++VIAgBjP99UL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports et variables"],"metadata":{"id":"f3mPeaGxctiJ"}},{"cell_type":"code","source":["!pip install segmentation-models"],"metadata":{"id":"mP8MOPYUe6QT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import albumentations as A\n","import shutil\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Set the SM_FRAMEWORK environment variable before importing segmentation_models\n","os.environ['SM_FRAMEWORK'] = 'tf.keras'\n","import segmentation_models as sm"],"metadata":{"id":"KlnFbaFWcwlq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib import rcParams\n","import matplotlib.font_manager as fm\n","font_path = os.path.expanduser(\"/content/drive/MyDrive/Colab Notebooks/fonts/Exo2-VariableFont_wght.ttf\")\n","fm.fontManager.addfont(font_path)\n","\n","# Définir la police globale avec le nom de la police\n","rcParams[\"font.family\"] = \"Exo 2\"\n","# deux couleurs pertinentes pour aller avec la présentation\n","bleuclair = (0.15, 0.55, 0.82)\n","couleur_complementaire = (1 - bleuclair[0], 1 - bleuclair[1], 1 - bleuclair[2])\n","bleufonce = \"#073642\""],"metadata":{"id":"I5p6iT0yNyHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imgPrezPath = '/content/drive/MyDrive/Colab Notebooks/Projet 8/img'"],"metadata":{"id":"RCVgkdr9N9c-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","  tf.config.experimental.set_memory_growth(gpu, True)"],"metadata":{"id":"SvGnDUB-V7cw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BACKBONE = 'resnet34'\n","preprocess_input = sm.get_preprocessing(BACKBONE)\n","print(preprocess_input.__doc__)"],"metadata":{"id":"8QYCgol2ENOJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Simule une image [0, 255] uint8\n","img = np.ones((2, 2, 3), dtype=np.uint8) * 255\n","\n","# Applique le preprocess_input\n","img_processed = preprocess_input(img.astype('float32'))\n","\n","print(img_processed)\n","print(\"min:\", img_processed.min(), \"max:\", img_processed.max())"],"metadata":{"id":"7cVI3P2rE_fX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Je vais charger mes fichiers sur le drive du Colab plutôt que sur le Google Drive monté sur l'environnement Colab : gain de temps testé à x2"],"metadata":{"id":"SWRZ3z7T86hB"}},{"cell_type":"code","source":["masksSourceFolder = '/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_gtFine_trainvaltest/gtFine8'\n","imagesSourceFolder = '/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit'"],"metadata":{"id":"Pp0W-Yl1c70U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["masksFolder = '/content/images'\n","imagesFolder = '/content/masks'"],"metadata":{"id":"H1fhCJxcQ-3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sources = [masksSourceFolder, imagesSourceFolder]\n","destinations = [masksFolder, imagesFolder]"],"metadata":{"id":"zh9Dsx46SMki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["splits = ['train', 'val', 'test']"],"metadata":{"id":"1ks5SCS1Rbdu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for split in splits:\n","  for source, destination in zip(sources, destinations):\n","    src_dir = os.path.join(source, split)\n","    dst_dir = os.path.join(destination, split)\n","    os.makedirs(destination, exist_ok=True)\n","    os.makedirs(dst_dir, exist_ok=True)\n","    for fichier in os.listdir(src_dir):\n","      if fichier.endswith(\"labelIds.png\") or fichier.endswith(\"leftImg8bit.png\"):\n","        shutil.copyfile(os.path.join(src_dir, fichier), os.path.join(dst_dir, fichier))"],"metadata":{"id":"yHGwzgAaRjhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_dir = os.path.join(imagesFolder, 'train')\n","y_train_dir = os.path.join(masksFolder, 'train')\n","\n","X_val_dir = os.path.join(imagesFolder, 'val')\n","y_val_dir = os.path.join(masksFolder, 'val')\n","\n","X_test_dir = os.path.join(imagesFolder, 'test')\n","y_test_dir = os.path.join(masksFolder, 'test')"],"metadata":{"id":"R9GdqE5pdgFS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dicoclasses = {0:'void',\n","               1:'flat',\n","               2:'construction',\n","               3:'object',\n","               4:'nature',\n","               5:'sky',\n","               6:'human',\n","               7:'vehicle',\n","              }"],"metadata":{"id":"yJwkact8INyW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loader"],"metadata":{"id":"8kv8GEDVb8Qy"}},{"cell_type":"markdown","source":["https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n","\n","https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb"],"metadata":{"id":"kDPoxq2Sb5oh"}},{"cell_type":"code","source":["# je dois faire du one hot encoding sur le mask pour pouvoir utiliser les métriques dans la compilation du modèle\n","def to_onehot(mask, num_classes=8):\n","    return tf.one_hot(mask, num_classes).numpy().astype(np.float32)"],"metadata":{"id":"iuOD-II0MJmc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# adapted from https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb\n","class Dataloader(tf.keras.utils.Sequence):\n","    \"\"\"Load data from dataset and form batches\n","\n","    Args:\n","        data_folder: folder where is data.\n","        batch_size: Integet number of images in batch.\n","        transform: albumentations.Compose.\n","        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n","    \"\"\"\n","\n","    def __init__(self, data_folder, batch_size=1, transform=None, shuffle=False):\n","        self.data_folder = data_folder\n","        if data_folder == X_train_dir:\n","            self.mask_folder = y_train_dir\n","        elif data_folder == X_val_dir:\n","            self.mask_folder = y_val_dir\n","        elif data_folder == X_test_dir:\n","            self.mask_folder = y_test_dir\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.transform = transform\n","        self.indexes = list(set([path[:path.rfind('_')] for path in os.listdir(data_folder) if path.endswith(\".png\") ]))\n","        self.mask_indexes = [os.path.join(self.mask_folder, path) for path in self.indexes]\n","        self.indexes = [os.path.join(data_folder, path) for path in self.indexes]\n","\n","        self.on_epoch_end()\n","\n","    def __getitem__(self, i):\n","\n","        # collect batch data\n","        start = i * self.batch_size\n","        stop = (i + 1) * self.batch_size\n","        images = []\n","        masks = []\n","        for j in range(start, stop):\n","            root_file = self.indexes[j]\n","            mask_file = self.mask_indexes[j]\n","            image_file = root_file + \"_leftImg8bit.png\"\n","            mask_file = mask_file + \"_gtFine_labelIds.png\"\n","            # on convertit les images en array numpy\n","            image = np.array(Image.open(image_file))\n","            mask = np.array(Image.open(mask_file))\n","            # Appliquer la transformation si elle est demandée\n","            if self.transform is not None:\n","                transformed = self.transform(image=image, mask=mask)\n","                image = transformed[\"image\"]\n","                mask = transformed[\"mask\"]\n","            # c'est à ce moment qu'on encode en one-hot\n","            mask = to_onehot(mask)\n","            # on les ajoute à leurs listes respectives\n","            images.append(image)\n","            masks.append(mask)\n","        # transpose list of lists\n","        # batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n","        image_batch = np.stack(images, axis=0)\n","        mask_batch = np.stack(masks, axis=0)\n","        # print(\"DEBUG | images\", image_batch.shape, image_batch.dtype)\n","        # print(\"DEBUG | masks \", mask_batch.shape, mask_batch.dtype)\n","        # print(\"DEBUG | unique mask values\", np.unique(mask_batch))\n","        return image_batch, mask_batch\n","\n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch\"\"\"\n","        return len(self.indexes) // self.batch_size\n","        # return int(np.ceil(len(self.indexes) / self.batch_size))\n","\n","\n","    def on_epoch_end(self):\n","        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n","        if self.shuffle:\n","          # On mélange les paires image/mask ENSEMBLE\n","          combined = list(zip(self.indexes, self.mask_indexes))\n","          np.random.shuffle(combined)\n","          self.indexes, self.mask_indexes = zip(*combined)\n","          # zip(*combined) retourne des tuples, donc si tu veux des listes :\n","          self.indexes = list(self.indexes)\n","          self.mask_indexes = list(self.mask_indexes)"],"metadata":{"id":"yPaiatyLec_4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Il va falloir ajouter la data augmentation et le preprocessing"],"metadata":{"id":"z90SXENIsusp"}},{"cell_type":"markdown","source":["https://albumentations.ai/docs/3-basic-usage/semantic-segmentation/"],"metadata":{"id":"o4WF1bBuL279"}},{"cell_type":"markdown","source":["https://albumentations.ai/docs/3-basic-usage/choosing-augmentations/"],"metadata":{"id":"UkZkBnty3269"}},{"cell_type":"markdown","source":["https://albumentations.ai/docs/api-reference/albumentations/augmentations/geometric/transforms/#ShiftScaleRotate"],"metadata":{"id":"ak0w8Thl8mVa"}},{"cell_type":"code","source":["train_transform = A.Compose([\n","    # 1. Cropping / Resize\n","    A.Resize(256, 512),\n","\n","    # 2. Basic Geometric (invariances basiques)\n","    A.HorizontalFlip(p=0.5),\n","    # Pas de flip vertical, pas de symétrie carrée (sauf imagerie satellite)\n","\n","    # 3. Dropout/Occlusion (pour la robustesse aux obstacles)\n","    # A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.2),\n","\n","    # 4. Color/Channel dropout (si tu veux vraiment rendre le modèle insensible à la couleur)\n","    # A.ToGray(p=0.1),\n","    # A.ChannelDropout(p=0.1),\n","\n","    # 5. Affine transformations\n","    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.05, rotate_limit=5, p=0.25),\n","\n","    # 6. Domain-Specific (effets météo, soleil, etc.)\n","    # A.RandomSunFlare(p=0.1),\n","    # A.RandomShadow(p=0.1),\n","    # A.RandomFog(p=0.05),\n","    # A.RandomRain(p=0.05),\n","    # A.RandomSnow(p=0.05),\n","    # Autres effets spécifiques :\n","    A.RandomBrightnessContrast(p=0.2),\n","    # A.GaussNoise(p=0.2),\n","\n","    # 7. Normalization (toujours à la fin)\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n","    A.Lambda(image=preprocess_input)\n","])\n","\n","\n","val_transform = A.Compose([\n","    A.Resize(256, 512),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n","    A.Lambda(image=preprocess_input)\n","])"],"metadata":{"id":"-KM8STIBsuEj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = Dataloader(\n","    data_folder=X_train_dir,\n","    batch_size=72,\n","    transform=train_transform,\n","    shuffle=True\n",")\n","\n","val_loader = Dataloader(\n","    data_folder=X_val_dir,\n","    batch_size=72,\n","    transform=val_transform,\n","    shuffle=False\n",")"],"metadata":{"id":"ytBW4TlNQPgD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["earlystop_cb = EarlyStopping(\n","    monitor='val_loss',\n","    patience=8,\n","    restore_best_weights=True\n",")"],"metadata":{"id":"QLmWjSHjRCFo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PerClassMetricsCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, val_loader, num_classes=8):\n","        # on initie d'abord le parent pour éviter les mauvaises surprises\n","        super().__init__()\n","        self.val_loader = val_loader\n","        self.num_classes = num_classes\n","        # on charge le dico des classes\n","        self.dicoclasses = dicoclasses or {i: f\"class_{i}\" for i in range(num_classes)}\n","        # on stocke les scores de chaque epoch dans un df\n","        self.df_scores = pd.DataFrame()\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # à chaque fin d'époque on calcule les métriques customs\n","        # d'abord on recueille les prédictions et la vérité\n","        all_preds = []\n","        all_trues = []\n","        for i in range(len(self.val_loader)):\n","            imgs, masks = self.val_loader[i]\n","            preds = self.model.predict(imgs, verbose=0)\n","            all_preds.append(preds)\n","            all_trues.append(masks)\n","        all_preds = np.concatenate(all_preds, axis=0)\n","        all_trues = np.concatenate(all_trues, axis=0)\n","        # on extrait la plus haute probabilité\n","        y_pred = np.argmax(all_preds, axis=-1)           # (n_samples, H, W)\n","        # on convertit aussi les ground truths en indices\n","        if all_trues.ndim == 4 and all_trues.shape[-1] > 1:\n","            y_true = np.argmax(all_trues, axis=-1)       # (n_samples, H, W)\n","        else:\n","            y_true = all_trues\n","\n","        dice_scores = []\n","        iou_scores = []\n","        for c in range(self.num_classes):\n","            y_true_c = (y_true == c).astype(np.int32)\n","            y_pred_c = (y_pred == c).astype(np.int32)\n","            intersection = (y_true_c * y_pred_c).sum()\n","            union = y_true_c.sum() + y_pred_c.sum()\n","            dice = (2. * intersection) / (union + 1e-6)\n","            dice_scores.append(dice)\n","\n","            union_iou = y_true_c.sum() + y_pred_c.sum() - intersection\n","            iou = (intersection) / (union_iou + 1e-6)\n","            iou_scores.append(iou)\n","\n","        # ajouts au dataframe de résultats\n","        row = {'epoch': epoch+1}\n","        for c, (d, iou) in enumerate(zip(dice_scores, iou_scores)):\n","            label = self.dicoclasses.get(c, f\"class_{c}\")\n","            row[f\"dice_{label}\"] = d\n","            row[f\"iou_{label}\"] = iou\n","        row['dice_mean'] = np.mean(dice_scores)\n","        row['iou_mean'] = np.mean(iou_scores)\n","\n","        self.df_scores = pd.concat([self.df_scores, pd.DataFrame([row])], ignore_index=True)\n","\n","\n","        print(f\"\\n=== Époque {epoch + 1} ===\")\n","        for c, (d, iou) in enumerate(zip(dice_scores, iou_scores)):\n","            className = dicoclasses.get(c, f\"class_{c}\")\n","            print(f\"{className} (classe {c}): Dice={d:.4f} | IoU={iou:.4f}\")\n","        print(f\"--- Dice moyen: {np.mean(dice_scores):.4f} | IoU moyen: {np.mean(iou_scores):.4f} ---\\n\")"],"metadata":{"id":"JLB24g8sAL9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["per_class_metrics_cb = PerClassMetricsCallback(val_loader=val_loader, num_classes=8)"],"metadata":{"id":"fVCOymLBAZKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=8, activation='softmax')\n","\n","\n","model.compile(\n","    'Adam',\n","    loss='categorical_crossentropy',\n","    metrics=[sm.metrics.iou_score],\n",")"],"metadata":{"id":"mLO1LbAFA2hH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","start_time = time.time()"],"metadata":{"id":"kqFo8kVpiLZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    train_loader,\n","    validation_data=val_loader,\n","    epochs=50,\n","    callbacks=[earlystop_cb, per_class_metrics_cb],\n","    verbose=1\n",")"],"metadata":{"id":"fX4Jt52TBm5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.ticker as mticker\n","\n","plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n","\n","plt.plot(history.history['loss'], label='train loss')\n","plt.plot(history.history['val_loss'], label='val loss')\n","plt.plot(history.history['iou_score'], label='train iou_score')\n","plt.plot(history.history['val_iou_score'], label='val iou_score')\n","plt.legend()\n","plt.tight_layout()\n","plt.savefig(os.path.join(imgPrezPath, \"UNet_resnet.svg\"),format=\"svg\",bbox_inches=\"tight\",pad_inches=0.1,)"],"metadata":{"id":"pg8H54PuONn8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["end_time = time.time()"],"metadata":{"id":"HK7Bf17BiRZo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print (end_time - start_time)"],"metadata":{"id":"pZbR33XtiTdo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Bath trop grand, et dans tous les cas, learning rate pas adapté"],"metadata":{"id":"bi6SQfvr_Mog"}}]}