{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1id2SLSUjyP3NMFd7Cx1XsDYQXl-Sj45e","authorship_tag":"ABX9TyOVThpO4FchtC4HrWa/w3ba"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports et variables"],"metadata":{"id":"f3mPeaGxctiJ"}},{"cell_type":"code","source":["import os\n","import cv2\n","import keras\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import albumentations as A\n","import shutil\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping"],"metadata":{"id":"KlnFbaFWcwlq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","  tf.config.experimental.set_memory_growth(gpu, True)"],"metadata":{"id":"SvGnDUB-V7cw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["masksSourceFolder = '/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_gtFine_trainvaltest/gtFine8'\n","imagesSourceFolder = '/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit'"],"metadata":{"id":"Pp0W-Yl1c70U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["masksFolder = '/content/images'\n","imagesFolder = '/content/masks'"],"metadata":{"id":"H1fhCJxcQ-3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sources = [masksSourceFolder, imagesSourceFolder]\n","destinations = [masksFolder, imagesFolder]"],"metadata":{"id":"zh9Dsx46SMki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["splits = ['train', 'val', 'test']"],"metadata":{"id":"1ks5SCS1Rbdu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for split in splits:\n","  for source, destination in zip(sources, destinations):\n","    src_dir = os.path.join(source, split)\n","    dst_dir = os.path.join(destination, split)\n","    os.makedirs(destination, exist_ok=True)\n","    os.makedirs(dst_dir, exist_ok=True)\n","    for fichier in os.listdir(src_dir):\n","      if fichier.endswith(\"labelIds.png\") or fichier.endswith(\"leftImg8bit.png\"):\n","        shutil.copyfile(os.path.join(src_dir, fichier), os.path.join(dst_dir, fichier))"],"metadata":{"id":"yHGwzgAaRjhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_dir = os.path.join(imagesFolder, 'train')\n","y_train_dir = os.path.join(masksFolder, 'train')\n","\n","X_val_dir = os.path.join(imagesFolder, 'val')\n","y_val_dir = os.path.join(masksFolder, 'val')\n","\n","X_test_dir = os.path.join(imagesFolder, 'test')\n","y_test_dir = os.path.join(masksFolder, 'test')"],"metadata":{"id":"R9GdqE5pdgFS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dicoclasses = {0:'void',\n","               1:'flat',\n","               2:'construction',\n","               3:'object',\n","               4:'nature',\n","               5:'sky',\n","               6:'human',\n","               7:'vehicle',\n","              }"],"metadata":{"id":"yJwkact8INyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iuOD-II0MJmc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loader"],"metadata":{"id":"8kv8GEDVb8Qy"}},{"cell_type":"markdown","source":["https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n","\n","https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb"],"metadata":{"id":"kDPoxq2Sb5oh"}},{"cell_type":"code","source":["# adapted from https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb\n","class Dataloader(keras.utils.Sequence):\n","    \"\"\"Load data from dataset and form batches\n","\n","    Args:\n","        data_folder: folder where is data.\n","        batch_size: Integet number of images in batch.\n","        transform: albumentations.Compose.\n","        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n","    \"\"\"\n","\n","    def __init__(self, data_folder, batch_size=1, transform=None, shuffle=False):\n","        self.data_folder = data_folder\n","        if data_folder == X_train_dir:\n","            self.mask_folder = y_train_dir\n","        elif data_folder == X_val_dir:\n","            self.mask_folder = y_val_dir\n","        elif data_folder == X_test_dir:\n","            self.mask_folder = y_test_dir\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.transform = transform\n","        self.indexes = list(set([path[:path.rfind('_')] for path in os.listdir(data_folder) if path.endswith(\".png\") ]))\n","        self.mask_indexes = [os.path.join(self.mask_folder, path) for path in self.indexes]\n","        self.indexes = [os.path.join(data_folder, path) for path in self.indexes]\n","\n","        self.on_epoch_end()\n","\n","    def __getitem__(self, i):\n","\n","        # collect batch data\n","        start = i * self.batch_size\n","        stop = (i + 1) * self.batch_size\n","        images = []\n","        masks = []\n","        for j in range(start, stop):\n","            root_file = self.indexes[j]\n","            mask_file = self.mask_indexes[j]\n","            image_file = root_file + \"_leftImg8bit.png\"\n","            mask_file = mask_file + \"_gtFine_labelIds.png\"\n","            # on convertit les images en array numpy\n","            image = np.array(Image.open(image_file))\n","            mask = np.array(Image.open(mask_file))\n","            # Appliquer la transformation si elle est demandée\n","            if self.transform is not None:\n","                transformed = self.transform(image=image, mask=mask)\n","                image = transformed[\"image\"]\n","                mask = transformed[\"mask\"]\n","            # on les ajoute à leurs listes respectives\n","            images.append(image)\n","            masks.append(mask)\n","        # transpose list of lists\n","        # batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n","        image_batch = np.stack(images, axis=0)\n","        mask_batch = np.stack(masks, axis=0)\n","        # print(\"DEBUG | images\", image_batch.shape, image_batch.dtype)\n","        # print(\"DEBUG | masks \", mask_batch.shape, mask_batch.dtype)\n","        # print(\"DEBUG | unique mask values\", np.unique(mask_batch))\n","        return image_batch, mask_batch\n","\n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch\"\"\"\n","        return len(self.indexes) // self.batch_size\n","        # return int(np.ceil(len(self.indexes) / self.batch_size))\n","\n","\n","    def on_epoch_end(self):\n","        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n","        if self.shuffle:\n","          # On mélange les paires image/mask ENSEMBLE\n","          combined = list(zip(self.indexes, self.mask_indexes))\n","          np.random.shuffle(combined)\n","          self.indexes, self.mask_indexes = zip(*combined)\n","          # zip(*combined) retourne des tuples, donc si tu veux des listes :\n","          self.indexes = list(self.indexes)\n","          self.mask_indexes = list(self.mask_indexes)"],"metadata":{"id":"yPaiatyLec_4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Il va falloir ajouter la data augmentation et le preprocessing"],"metadata":{"id":"z90SXENIsusp"}},{"cell_type":"markdown","source":["https://albumentations.ai/docs/3-basic-usage/semantic-segmentation/"],"metadata":{"id":"o4WF1bBuL279"}},{"cell_type":"markdown","source":["https://albumentations.ai/docs/3-basic-usage/choosing-augmentations/"],"metadata":{"id":"UkZkBnty3269"}},{"cell_type":"markdown","source":["https://albumentations.ai/docs/api-reference/albumentations/augmentations/geometric/transforms/#ShiftScaleRotate"],"metadata":{"id":"ak0w8Thl8mVa"}},{"cell_type":"code","source":["train_transform = A.Compose([\n","    # 1. Cropping / Resize\n","    A.Resize(256, 512),\n","\n","    # 2. Basic Geometric (invariances basiques)\n","    A.HorizontalFlip(p=0.5),\n","    # Pas de flip vertical, pas de symétrie carrée (sauf imagerie satellite)\n","\n","    # 3. Dropout/Occlusion (pour la robustesse aux obstacles)\n","    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.2),\n","\n","    # 4. Color/Channel dropout (si tu veux vraiment rendre le modèle insensible à la couleur)\n","    # A.ToGray(p=0.1),\n","    A.ChannelDropout(p=0.1),\n","\n","    # 5. Affine transformations\n","    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),\n","\n","    # 6. Domain-Specific (effets météo, soleil, etc.)\n","    A.RandomSunFlare(p=0.1),\n","    A.RandomShadow(p=0.1),\n","    A.RandomFog(p=0.05),\n","    A.RandomRain(p=0.05),\n","    A.RandomSnow(p=0.05),\n","    # Autres effets spécifiques :\n","    A.RandomBrightnessContrast(p=0.3),\n","    A.GaussNoise(p=0.2),\n","\n","    # 7. Normalization (toujours à la fin)\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0)\n","])\n","\n","\n","val_transform = A.Compose([\n","    A.Resize(256, 512),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0)\n","])"],"metadata":{"id":"-KM8STIBsuEj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = Dataloader(\n","    data_folder=X_train_dir,\n","    batch_size=8,\n","    transform=train_transform,\n","    shuffle=True\n",")\n","\n","val_loader = Dataloader(\n","    data_folder=X_val_dir,\n","    batch_size=8,\n","    transform=val_transform,\n","    shuffle=False\n",")"],"metadata":{"id":"ytBW4TlNQPgD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fonctions de visualisation pour vérifier le comportement de l'augmentation\n","# Simple function to overlay mask on image for visualization\n","def overlay_mask(image, mask, alpha=0.5, color=(0, 1, 0)): # Green overlay\n","    # Convert mask to 3 channels if needed, ensure boolean type\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    # Create a color overlay where mask is > 0\n","    mask_overlay[mask > 0] = (np.array(color) * 255).astype(np.uint8)\n","\n","    # Blend image and overlay\n","    overlayed_image = cv2.addWeighted(image, 1, mask_overlay, alpha, 0)\n","    return overlayed_image\n","\n","def visualize_segmentation(dataset, idx=0, samples=3):\n","    import matplotlib.pyplot as plt\n","\n","    if isinstance(dataset.transform, A.Compose):\n","        vis_transform_list = [\n","            t for t in dataset.transform\n","            if not isinstance(t, (A.Normalize, A.ToTensorV2))\n","        ]\n","        vis_transform = A.Compose(vis_transform_list)\n","    else:\n","        print(\"Warning: Could not automatically strip Normalize/ToTensor for visualization.\")\n","        vis_transform = dataset.transform\n","\n","    figure, ax = plt.subplots(samples + 1, 2, figsize=(8, 4 * (samples + 1)))\n","\n","    # --- Get the original image and mask --- #\n","    original_transform = dataset.transform\n","    dataset.transform = None # Temporarily disable for raw data access\n","    image_batch, mask_batch = dataset[idx]\n","    image = image_batch[0]   # Prends la première image du batch\n","    mask = mask_batch[0]     # Prends le premier masque du batch\n","    dataset.transform = original_transform # Restore\n","\n","    # --- Patch : assure l'image est (H,W,3) uint8 --- #\n","    if image.ndim == 2: # grayscale\n","        image = np.stack([image]*3, axis=-1)\n","    if image.ndim == 3 and image.shape[2] == 1:\n","        image = np.repeat(image, 3, axis=2)\n","    if image.dtype != np.uint8:\n","        image = image.astype(np.uint8)\n","    # --- Patch masque (H,W) --- #\n","    if mask.ndim == 3:\n","        mask = mask.squeeze()\n","    # Affichage original\n","    ax[0, 0].imshow(image)\n","    ax[0, 0].set_title(\"Original Image\")\n","    ax[0, 0].axis(\"off\")\n","    ax[0, 1].imshow(mask, cmap='gray')\n","    ax[0, 1].set_title(\"Original Mask\")\n","    ax[0, 1].axis(\"off\")\n","\n","    # --- Apply and display augmented versions --- #\n","    for i in range(samples):\n","        # Applique la transformation de visu\n","        if vis_transform:\n","            augmented = vis_transform(image=image, mask=mask)\n","            aug_image = augmented['image']\n","            aug_mask = augmented['mask']\n","        else:\n","            aug_image, aug_mask = image, mask\n","\n","        # PATCH : force format image/mask\n","        if aug_image.ndim == 2:\n","            aug_image = np.stack([aug_image]*3, axis=-1)\n","        if aug_image.ndim == 3 and aug_image.shape[2] == 1:\n","            aug_image = np.repeat(aug_image, 3, axis=2)\n","        if aug_image.dtype != np.uint8:\n","            aug_image = aug_image.astype(np.uint8)\n","        if aug_mask.ndim == 3:\n","            aug_mask = aug_mask.squeeze()\n","\n","        ax[i + 1, 0].imshow(aug_image)\n","        ax[i + 1, 0].set_title(f\"Augmented Image {i+1}\")\n","        ax[i + 1, 0].axis(\"off\")\n","\n","        ax[i + 1, 1].imshow(aug_mask, cmap='gray')\n","        ax[i + 1, 1].set_title(f\"Augmented Mask {i+1}\")\n","        ax[i + 1, 1].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n"],"metadata":{"id":"kDYVerD-QcHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize_segmentation(train_loader, samples=3)"],"metadata":{"id":"qsJm57WMQj4j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_batch(dataset, idx=0, n=5):\n","    \"\"\"\n","    Visualise n paires image/masque d’un batch donné du DataLoader.\n","    \"\"\"\n","    # On récupère un batch d'index idx (un lot d'images et de masques)\n","    images, masks = dataset[idx]\n","    # images.shape = (batch_size, H, W, C)\n","    # on extrait donc la batch size ainsi\n","    batch_size = images.shape[0]\n","    # on fait attention, si le batch a moins d'élements que de paires demandées, on recalibre le nombre de paires demandées\n","    n = min(n, batch_size)\n","\n","    # on va faire les subplots pour toutes les paires images et masks\n","\n","    plt.figure(figsize=(6, 2 * n))\n","    for i in range(n):\n","        # colonne de gauche : image\n","        plt.subplot(n, 2, 2 * i + 1)\n","        img = images[i]\n","        # Si l’image est grayscale (juste 2D, shape (H, W)), on la duplique sur 3 canaux pour obtenir (H, W, 3)\n","        if img.ndim == 2:\n","            img = np.stack([img]*3, axis=-1)\n","        # Si l’image est au format (H, W, 1) (toujours grayscale mais avec une dimension \"canal\" explicite), on la répète sur 3 canaux pour obtenir (H, W, 3)\n","        if img.ndim == 3 and img.shape[2] == 1:\n","            img = np.repeat(img, 3, axis=2)\n","        if img.dtype != np.uint8:\n","            img = img.astype(np.uint8)\n","        plt.imshow(img)\n","        plt.axis(\"off\")\n","        plt.title(f\"Image {i}\")\n","        # colonne de droite : mask\n","        plt.subplot(n, 2, 2 * i + 2)\n","        mask = masks[i]\n","        # Au cas où le nombre de channels (1) du mask est indiqué\n","        if mask.ndim == 3:\n","            mask = mask.squeeze()\n","        plt.imshow(mask, cmap='tab20')  # 'tab20' pour mieux voir les classes, sinon 'nipy_spectral'\n","        plt.axis(\"off\")\n","        plt.title(f\"Mask {i}\")\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"LdvCvCwpUnMY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_batch(train_loader, idx=0, n=5)"],"metadata":{"id":"Y9RLxxdOUpw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_unique_mask_values(dataset, idx=0):\n","    \"\"\"\n","    Affiche les valeurs uniques de chaque masque d’un batch (par défaut premier batch).\n","    \"\"\"\n","    _, masks = dataset[idx]\n","    for i, mask in enumerate(masks):\n","        uniques = np.unique(mask)\n","        print(f\"Masque {i} : valeurs uniques {uniques}\")\n"],"metadata":{"id":"iOXkc8f7UwAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_unique_mask_values(train_loader, idx=0)\n"],"metadata":{"id":"uDJ-1MfdUxio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_all_unique_mask_values(dataset):\n","    \"\"\"\n","    Affiche les valeurs uniques globales pour tous les masques du dataset.\n","    \"\"\"\n","    all_uniques = set()\n","    for idx in range(len(dataset)):\n","        _, masks = dataset[idx]\n","        for mask in masks:\n","            all_uniques.update(np.unique(mask))\n","    print(f\"Valeurs uniques globales sur tous les masques : {sorted(all_uniques)}\")\n"],"metadata":{"id":"fx7FMrSnU0yD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print_all_unique_mask_values(train_loader)\n"],"metadata":{"id":"t1fMizPbU2Du"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_batch(train_loader, idx=4, n=7)"],"metadata":{"id":"j3uFJfW9eQS5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Baseline\n","\n","https://github.com/zhixuhao/unet/blob/master/model.py\n","\n","Je vais devoir modifier à la fois l'input et la sortie\n","\n","https://keras.io/api/metrics/segmentation_metrics/\n","\n"],"metadata":{"id":"oEWFrNRy_kbm"}},{"cell_type":"code","source":["import skimage.io as io\n","import skimage.transform as trans\n","\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler"],"metadata":{"id":"rbv0HrG7AxPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unet(pretrained_weights = None,input_size = (256,512,3)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    # la couche suivante n'est pas pertinente pour du multiclasse\n","    # conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    # ici je doix changer conv10 pour avoir huit catégories, et donc utiliser softmax en activation\n","    conv10 = Conv2D(8, 1, activation='softmax')(conv9)\n","\n","    model = Model(inputs = inputs, outputs = conv10)\n","\n","    # pour du multiclasse qui n'est pas en one-hot encoding, loss est SCCE\n","    # je dois aussi ajouter des métriques\n","    model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    # model.summary()\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model"],"metadata":{"id":"qVaLG2NJ_kEK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = Dataloader(\n","    data_folder=X_train_dir,\n","    batch_size=8,\n","    transform=val_transform,\n","    shuffle=True\n",")\n","\n","val_loader = Dataloader(\n","    data_folder=X_val_dir,\n","    batch_size=8,\n","    transform=val_transform,\n","    shuffle=False\n",")"],"metadata":{"id":"GdAYiCOfJtr_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = unet()"],"metadata":{"id":"GKj7DzAOJ99r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imgs, masks = next(iter(train_loader))\n","print(\"images shape\", imgs.shape)\n","print(\"masks shape\", masks.shape)\n","print(\"mask unique\", np.unique(masks), masks.dtype)"],"metadata":{"id":"Y1LqAIFweC5A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Callbacks"],"metadata":{"id":"dhBAfVZgQ_pm"}},{"cell_type":"code","source":["earlystop_cb = EarlyStopping(\n","    monitor='val_loss',\n","    patience=8,\n","    restore_best_weights=True\n",")"],"metadata":{"id":"QLmWjSHjRCFo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PerClassMetricsCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, val_loader, num_classes=8):\n","        # on initie d'abord le parent pour éviter les mauvaises surprises\n","        super().__init__()\n","        self.val_loader = val_loader\n","        self.num_classes = num_classes\n","        # on charge le dico des classes\n","        self.dicoclasses = dicoclasses or {i: f\"class_{i}\" for i in range(num_classes)}\n","        # on stocke les scores de chaque epoch dans un df\n","        self.df_scores = pd.DataFrame()\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # à chaque fin d'époque on calcule les métriques customs\n","        # d'abord on recueille les prédictions et la vérité\n","        all_preds = []\n","        all_trues = []\n","        for i in range(len(self.val_loader)):\n","            imgs, masks = self.val_loader[i]\n","            preds = self.model.predict(imgs, verbose=0)\n","            all_preds.append(preds)\n","            all_trues.append(masks)\n","        all_preds = np.concatenate(all_preds, axis=0)\n","        all_trues = np.concatenate(all_trues, axis=0)\n","        # on extrait la plus haute probabilité\n","        y_pred = np.argmax(all_preds, axis=-1)\n","\n","        # Calcul Dice & IoU par classe\n","        # attention l'union dans le Dice et l'IoU n'est pas la même chose\n","        # dans le Dice il s'agit de la somme des cardinaux des ensembles\n","        dice_scores = []\n","        iou_scores = []\n","        for c in range(self.num_classes):\n","            # on créé des masques binaires pour pouvoir appliquer facilement nos formules\n","            # tous les pixels correspondant à la classe c sont 1, les autres sont 0\n","            y_true_c = (all_trues == c).astype(np.int32)\n","            y_pred_c = (y_pred == c).astype(np.int32)\n","            intersection = (y_true_c * y_pred_c).sum()\n","            union = y_true_c.sum() + y_pred_c.sum()\n","            dice = (2. * intersection) / (union + 1e-6)\n","            dice_scores.append(dice)\n","\n","            union_iou = y_true_c.sum() + y_pred_c.sum() - intersection\n","            iou = (intersection) / (union_iou + 1e-6)\n","            iou_scores.append(iou)\n","\n","        # ajouts au dataframe de résultats\n","        row = {'epoch': epoch+1}\n","        for c, (d, iou) in enumerate(zip(dice_scores, iou_scores)):\n","            label = self.dicoclasses.get(c, f\"class_{c}\")\n","            row[f\"dice_{label}\"] = d\n","            row[f\"iou_{label}\"] = iou\n","        row['dice_mean'] = np.mean(dice_scores)\n","        row['iou_mean'] = np.mean(iou_scores)\n","\n","        self.df_scores = pd.concat([self.df_scores, pd.DataFrame([row])], ignore_index=True)\n","\n","\n","        print(f\"\\n=== Époque {epoch + 1} ===\")\n","        for c, (d, iou) in enumerate(zip(dice_scores, iou_scores)):\n","            className = dicoclasses.get(c, f\"class_{c}\")\n","            print(f\"{className} (classe {c}): Dice={d:.4f} | IoU={iou:.4f}\")\n","        print(f\"--- Dice moyen: {np.mean(dice_scores):.4f} | IoU moyen: {np.mean(iou_scores):.4f} ---\\n\")\n"],"metadata":{"id":"Ql3z3VBZgbRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["per_class_metrics_cb = PerClassMetricsCallback(val_loader=val_loader, num_classes=8)"],"metadata":{"id":"z2man9hARVTx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fit et graphiques"],"metadata":{"id":"CjgmuRxdRXeI"}},{"cell_type":"code","source":["history = model.fit(\n","    train_loader,\n","    validation_data=val_loader,\n","    epochs=50,\n","    callbacks=[earlystop_cb, per_class_metrics_cb],\n","    verbose=1\n",")\n"],"metadata":{"id":"va3nfmp8J6Bz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['loss'], label='train loss')\n","plt.plot(history.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"r2_UjgzIQprl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Récupère les scores du callback\n","df = per_class_metrics_cb.df_scores\n","\n","# Exemple : courbe Dice moyen sur la validation\n","plt.plot(df['epoch'], df['dice_mean'], label='Val Dice')\n","plt.plot(history.history['dice_coef'], label='Train Dice')  # si tu as mis dice_coef dans metrics\n","plt.legend()\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Dice\")\n","plt.title(\"Courbe Dice train/val\")\n","plt.show()\n","\n","# Pareil pour la loss, l'IoU, etc.\n"],"metadata":{"id":"q_Uy-8nPQgyv"},"execution_count":null,"outputs":[]}]}