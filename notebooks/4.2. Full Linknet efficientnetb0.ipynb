{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GamMJuYCglVRPM2PbGk6C9_4crksqpWr","timestamp":1750767089660},{"file_id":"15ZnmzhonnoeYBbjGepV42S85RGMdBker","timestamp":1750714790675}],"machine_shape":"hm","gpuType":"L4","mount_file_id":"1zveVHFBOChH6ZMF4h0y2QkM_vOtECZzL","authorship_tag":"ABX9TyOg3wCYGmfvY4u9GLbQfRQv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eF0jHfsjbUYU","collapsed":true},"outputs":[],"source":["!pip install segmentation-models dagshub mlflow"]},{"cell_type":"code","source":["import os\n","import cv2\n","from google.colab import userdata\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mticker\n","\n","import dagshub\n","import mlflow\n","import pickle\n","\n","from PIL import Image\n","import albumentations as A\n","import shutil\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import backend as K\n","\n","import gc\n","\n","# Set the SM_FRAMEWORK environment variable before importing segmentation_models\n","os.environ['SM_FRAMEWORK'] = 'tf.keras'\n","\n","import segmentation_models as sm\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","  tf.config.experimental.set_memory_growth(gpu, True)"],"metadata":{"id":"PNzC_0X3bcl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Récupère automatiquement le secret\n","dagshub_token = userdata.get('DAGSHUB_TOKEN')\n","\n","# Initialisation Dagshub\n","dagshub.auth.add_app_token(dagshub_token)\n","\n","# Connecter MLflow à Dagshub\n","dagshub.init(repo_owner='fabiencappelli', repo_name='Projet_08', mlflow=True)\n","\n","from matplotlib import rcParams\n","import matplotlib.font_manager as fm\n","font_path = os.path.expanduser(\"/content/drive/MyDrive/Colab Notebooks/fonts/Exo2-VariableFont_wght.ttf\")\n","fm.fontManager.addfont(font_path)\n","\n","# Définir la police globale avec le nom de la police\n","rcParams[\"font.family\"] = \"Exo 2\"\n","# deux couleurs pertinentes pour aller avec la présentation\n","bleuclair = (0.15, 0.55, 0.82)\n","couleur_complementaire = (1 - bleuclair[0], 1 - bleuclair[1], 1 - bleuclair[2])\n","bleufonce = \"#073642\""],"metadata":{"id":"EQQn1PLVd5ch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imgPrezPath = '/content/drive/MyDrive/Colab Notebooks/Projet 8/img'\n","masksSourceFolder = '/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_gtFine_trainvaltest/gtFine8'\n","imagesSourceFolder = '/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit'\n","masksFolder = '/content/images'\n","imagesFolder = '/content/masks'"],"metadata":{"id":"SlwkkEYIwLzd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sources = [masksSourceFolder, imagesSourceFolder]\n","destinations = [masksFolder, imagesFolder]\n","splits = ['train', 'val']"],"metadata":{"id":"zh9Dsx46SMki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for split in splits:\n","  for source, destination in zip(sources, destinations):\n","    src_dir = os.path.join(source, split)\n","    dst_dir = os.path.join(destination, split)\n","    os.makedirs(destination, exist_ok=True)\n","    os.makedirs(dst_dir, exist_ok=True)\n","    for fichier in os.listdir(src_dir):\n","      if fichier.endswith(\"labelIds.png\") or fichier.endswith(\"leftImg8bit.png\"):\n","        shutil.copyfile(os.path.join(src_dir, fichier), os.path.join(dst_dir, fichier))"],"metadata":{"id":"hgdLxtucwVPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BACKBONE = 'efficientnetb0'"],"metadata":{"id":"49cE6AVAqF9L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocess_input = sm.get_preprocessing(BACKBONE)"],"metadata":{"id":"q1UlXvYpf3OA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataloader"],"metadata":{"id":"zKVCu8jzgmNV"}},{"cell_type":"code","source":["dicoclasses = {0:'void',\n","               1:'flat',\n","               2:'construction',\n","               3:'object',\n","               4:'nature',\n","               5:'sky',\n","               6:'human',\n","               7:'vehicle',\n","              }\n","\n","def to_onehot(mask, num_classes=8):\n","    return tf.one_hot(mask, num_classes).numpy().astype(np.float32)\n","\n","# adapted from https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb\n","class Dataloader(tf.keras.utils.Sequence):\n","    \"\"\"Load data from dataset and form batches\n","\n","    Args:\n","        data_folder: folder where is data.\n","        batch_size: Integet number of images in batch.\n","        transform: albumentations.Compose.\n","        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n","    \"\"\"\n","\n","    def __init__(self, data_folder, batch_size=1, transform=None, shuffle=False):\n","        self.data_folder = data_folder\n","        if data_folder == X_train_dir:\n","            self.mask_folder = y_train_dir\n","        elif data_folder == X_val_dir:\n","            self.mask_folder = y_val_dir\n","        elif data_folder == X_test_dir:\n","            self.mask_folder = y_test_dir\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.transform = transform\n","        self.indexes = list(set([path[:path.rfind('_')] for path in os.listdir(data_folder) if path.endswith(\".png\") ]))\n","        self.mask_indexes = [os.path.join(self.mask_folder, path) for path in self.indexes]\n","        self.indexes = [os.path.join(data_folder, path) for path in self.indexes]\n","\n","        self.on_epoch_end()\n","\n","    def __getitem__(self, i):\n","\n","        # collect batch data\n","        start = i * self.batch_size\n","        stop = (i + 1) * self.batch_size\n","        images = []\n","        masks = []\n","        for j in range(start, stop):\n","            root_file = self.indexes[j]\n","            mask_file = self.mask_indexes[j]\n","            image_file = root_file + \"_leftImg8bit.png\"\n","            mask_file = mask_file + \"_gtFine_labelIds.png\"\n","            # on convertit les images en array numpy\n","            image = np.array(Image.open(image_file))\n","            mask = np.array(Image.open(mask_file))\n","            # Appliquer la transformation si elle est demandée\n","            if self.transform is not None:\n","                transformed = self.transform(image=image, mask=mask)\n","                image = transformed[\"image\"]\n","                mask = transformed[\"mask\"]\n","            # c'est à ce moment qu'on encode en one-hot\n","            mask = to_onehot(mask)\n","            # on les ajoute à leurs listes respectives\n","            images.append(image)\n","            masks.append(mask)\n","        # transpose list of lists\n","        # batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n","        image_batch = np.stack(images, axis=0)\n","        mask_batch = np.stack(masks, axis=0)\n","        # print(\"DEBUG | images\", image_batch.shape, image_batch.dtype)\n","        # print(\"DEBUG | masks \", mask_batch.shape, mask_batch.dtype)\n","        # print(\"DEBUG | unique mask values\", np.unique(mask_batch))\n","        return image_batch, mask_batch\n","\n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch\"\"\"\n","        return len(self.indexes) // self.batch_size\n","        # return int(np.ceil(len(self.indexes) / self.batch_size))\n","\n","\n","    def on_epoch_end(self):\n","        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n","        if self.shuffle:\n","          # On mélange les paires image/mask ENSEMBLE\n","          combined = list(zip(self.indexes, self.mask_indexes))\n","          np.random.shuffle(combined)\n","          self.indexes, self.mask_indexes = zip(*combined)\n","          # zip(*combined) retourne des tuples, donc si tu veux des listes :\n","          self.indexes = list(self.indexes)\n","          self.mask_indexes = list(self.mask_indexes)\n","\n","train_transform = A.Compose([\n","    # 1. Cropping / Resize\n","    A.Resize(256, 512),\n","\n","    # 2. Basic Geometric (invariances basiques)\n","    # A.HorizontalFlip(p=0.5),\n","    # Pas de flip vertical, pas de symétrie carrée (sauf imagerie satellite)\n","\n","    # 3. Dropout/Occlusion (pour la robustesse aux obstacles)\n","    # A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.2),\n","\n","    # 4. Color/Channel dropout (si tu veux vraiment rendre le modèle insensible à la couleur)\n","    # A.ToGray(p=0.1),\n","    # A.ChannelDropout(p=0.1),\n","\n","    # 5. Affine transformations\n","    # A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.05, rotate_limit=5, p=0.25),\n","\n","    # 6. Domain-Specific (effets météo, soleil, etc.)\n","    # A.RandomSunFlare(p=0.1),\n","    # A.RandomShadow(p=0.1),\n","    # A.RandomFog(p=0.05),\n","    # A.RandomRain(p=0.05),\n","    # A.RandomSnow(p=0.05),\n","    # Autres effets spécifiques :\n","    A.RandomBrightnessContrast(p=0.2),\n","    # A.GaussNoise(p=0.2),\n","\n","    # 7. Normalization (toujours à la fin)\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n","    A.Lambda(image=preprocess_input)\n","])\n","\n","\n","val_transform = A.Compose([\n","    A.Resize(256, 512),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n","    A.Lambda(image=preprocess_input)\n","])"],"metadata":{"id":"KLX5m9TXgAdL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Callbacks"],"metadata":{"id":"GoG2M2NMgjAX"}},{"cell_type":"code","source":["earlystop_cb = EarlyStopping(\n","    monitor='val_loss',\n","    patience=8,\n","    restore_best_weights=True\n",")\n","\n","lr_callback = ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.5,\n","    patience=3,\n","    verbose=1,\n","    min_lr=1e-6\n",")\n","\n","class PerClassMetricsCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, val_loader, num_classes=8):\n","        # on initie d'abord le parent pour éviter les mauvaises surprises\n","        super().__init__()\n","        self.val_loader = val_loader\n","        self.num_classes = num_classes\n","        # on charge le dico des classes\n","        self.dicoclasses = dicoclasses or {i: f\"class_{i}\" for i in range(num_classes)}\n","        # on stocke les scores de chaque epoch dans un df\n","        self.df_scores = pd.DataFrame()\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # à chaque fin d'époque on calcule les métriques customs\n","        # d'abord on recueille les prédictions et la vérité\n","        all_preds = []\n","        all_trues = []\n","        for i in range(len(self.val_loader)):\n","            imgs, masks = self.val_loader[i]\n","            preds = self.model.predict(imgs, verbose=0)\n","            all_preds.append(preds)\n","            all_trues.append(masks)\n","        all_preds = np.concatenate(all_preds, axis=0)\n","        all_trues = np.concatenate(all_trues, axis=0)\n","        # on extrait la plus haute probabilité\n","        y_pred = np.argmax(all_preds, axis=-1)           # (n_samples, H, W)\n","        # on convertit aussi les ground truths en indices\n","        if all_trues.ndim == 4 and all_trues.shape[-1] > 1:\n","            y_true = np.argmax(all_trues, axis=-1)       # (n_samples, H, W)\n","        else:\n","            y_true = all_trues\n","\n","        dice_scores = []\n","        iou_scores = []\n","        for c in range(self.num_classes):\n","            y_true_c = (y_true == c).astype(np.int32)\n","            y_pred_c = (y_pred == c).astype(np.int32)\n","            intersection = (y_true_c * y_pred_c).sum()\n","            union = y_true_c.sum() + y_pred_c.sum()\n","            dice = (2. * intersection) / (union + 1e-6)\n","            dice_scores.append(dice)\n","\n","            union_iou = y_true_c.sum() + y_pred_c.sum() - intersection\n","            iou = (intersection) / (union_iou + 1e-6)\n","            iou_scores.append(iou)\n","\n","        # ajouts au dataframe de résultats\n","        row = {'epoch': epoch+1}\n","        for c, (d, iou) in enumerate(zip(dice_scores, iou_scores)):\n","            label = self.dicoclasses.get(c, f\"class_{c}\")\n","            row[f\"dice_{label}\"] = d\n","            row[f\"iou_{label}\"] = iou\n","        row['dice_mean'] = np.mean(dice_scores)\n","        row['iou_mean'] = np.mean(iou_scores)\n","\n","        self.df_scores = pd.concat([self.df_scores, pd.DataFrame([row])], ignore_index=True)\n","\n","\n","        print(f\"\\n=== Époque {epoch + 1} ===\")\n","        for c, (d, iou) in enumerate(zip(dice_scores, iou_scores)):\n","            className = dicoclasses.get(c, f\"class_{c}\")\n","            print(f\"{className} (classe {c}): Dice={d:.4f} | IoU={iou:.4f}\")\n","        print(f\"--- Dice moyen: {np.mean(dice_scores):.4f} | IoU moyen: {np.mean(iou_scores):.4f} ---\\n\")\n","\n"],"metadata":{"id":"K7tTUdQcgQFv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fit sur dataset complet"],"metadata":{"id":"cm7HJkBLgwRl"}},{"cell_type":"code","source":["DECODER = 'Linknet'"],"metadata":{"id":"lxxH5nIcpVTD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import glob\n","import time"],"metadata":{"id":"juvDovULBcr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_dir = os.path.join(imagesFolder, 'train')\n","y_train_dir = os.path.join(masksFolder, 'train')\n","\n","X_val_dir = os.path.join(imagesFolder, 'val')\n","y_val_dir = os.path.join(masksFolder, 'val')\n","\n","train_imgs = sorted(glob.glob(os.path.join(X_train_dir, \"*_leftImg8bit.png\")))\n","train_masks = sorted(glob.glob(os.path.join(y_train_dir, \"*_gtFine_labelIds.png\")))\n","\n","assert len(train_imgs) == len(train_masks), \"Mismatch images/masks\"\n","\n","# Split 90% train / 10% test (val déjà à part)\n","train_imgs_new, test_imgs_new, train_masks_new, test_masks_new = train_test_split(\n","    train_imgs, train_masks, test_size=0.1, random_state=34\n",")\n","\n","os.makedirs(os.path.join(imagesFolder, 'test'), exist_ok=True)\n","os.makedirs(os.path.join(masksFolder, 'test'), exist_ok=True)\n","\n","X_test_dir = os.path.join(imagesFolder, 'test')\n","y_test_dir = os.path.join(masksFolder, 'test')\n","\n","for img, mask in zip(test_imgs_new, test_masks_new):\n","    shutil.move(img, X_test_dir)\n","    shutil.move(mask, y_test_dir)"],"metadata":{"id":"nMyPZ4o1fcxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 8\n","learning_rate = 1e-3\n","\n","train_loader = Dataloader(\n","    data_folder=X_train_dir,\n","    batch_size=batch_size,\n","    transform=train_transform,\n","    shuffle=True\n",")\n","val_loader = Dataloader(\n","    data_folder=X_val_dir,\n","    batch_size=batch_size,\n","    transform=val_transform,\n","    shuffle=False\n",")\n","test_loader = Dataloader(\n","    data_folder=X_test_dir,\n","    batch_size=4,\n","    transform=val_transform,\n","    shuffle=False\n",")\n","per_class_metrics_cb = PerClassMetricsCallback(val_loader=val_loader, num_classes=8)\n","optimizer = Adam(learning_rate=learning_rate)\n","model = sm.Linknet(BACKBONE, encoder_weights='imagenet', classes=8, activation='softmax')\n","model.compile(\n","    optimizer,\n","    loss='categorical_crossentropy',\n","    metrics=[sm.metrics.iou_score],\n",")\n","EXPERIMENT = 'FULL_' + BACKBONE + '_' + DECODER + '_BS_' + str(batch_size) + '_LR_' + str(learning_rate)\n","mlflow.set_experiment(EXPERIMENT)\n","with mlflow.start_run():\n","    history = model.fit(\n","        train_loader,\n","        validation_data=val_loader,\n","        epochs=50,\n","        callbacks=[earlystop_cb, per_class_metrics_cb, lr_callback],\n","        verbose=1\n","    )\n","    # Log des hyperparamètres :\n","    mlflow.log_param(\"batch_size\", batch_size)\n","    mlflow.log_param(\"lr\", learning_rate)\n","    # Log des métriques epoch par epoch :\n","    for epoch, (loss, val_loss, iou, val_iou) in enumerate(zip(\n","        history.history['loss'],\n","        history.history['val_loss'],\n","        history.history['iou_score'],\n","        history.history['val_iou_score']\n","    )):\n","        mlflow.log_metric(\"loss\", loss, step=epoch)\n","        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n","        mlflow.log_metric(\"iou_score\", iou, step=epoch)\n","        mlflow.log_metric(\"val_iou_score\", val_iou, step=epoch)\n","    # Sauvegarde de l'objet history complet :\n","    with open(\"history.pkl\", \"wb\") as f:\n","        pickle.dump(history.history, f)\n","    mlflow.log_artifact(\"history.pkl\")\n","    # Instancie la métrique IoU fournie par segmentation_models\n","    iou_metric = sm.metrics.IOUScore()\n","\n","    start_time = time.time()\n","    n_samples = 0\n","\n","    all_preds, all_trues = [], []\n","\n","    for imgs, masks in test_loader:\n","        preds = model.predict(imgs)\n","        all_preds.append(preds)\n","        all_trues.append(masks)\n","        n_samples += imgs.shape[0]\n","\n","    y_pred = tf.concat(all_preds, axis=0)\n","    y_true = tf.concat(all_trues, axis=0)\n","\n","    elapsed_time = time.time() - start_time\n","    avg_inference_time = elapsed_time / n_samples\n","\n","    mean_iou_test = sm.metrics.iou_score(y_true, y_pred).numpy()\n","\n","    mlflow.log_metric(\"test_avg_inference_time\", avg_inference_time)\n","    mlflow.log_metric(\"test_mean_iou\", mean_iou_test)\n","\n"],"metadata":{"id":"O7tXigqYZPvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure()\n","\n","plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n","plt.plot(history.history['loss'], label='train loss')\n","plt.plot(history.history['val_loss'], label='val loss')\n","plt.plot(history.history['iou_score'], label='train IoU_score')\n","plt.plot(history.history['val_iou_score'], label='val IoU_score')\n","plt.axhline(mean_iou_test, color='purple', linestyle='--', label=f'test IoU={mean_iou_test:.3f}')\n","\n","plt.legend()\n","plt.title(EXPERIMENT + ' avec augmentation')\n","plt.xlabel('Époques')\n","plt.ylabel('Valeurs')\n","plt.tight_layout()\n","plt.savefig(os.path.join(imgPrezPath, EXPERIMENT +'.svg'),format=\"svg\",bbox_inches=\"tight\",pad_inches=0.1,)"],"metadata":{"id":"AeBixbiVPIz0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save('/content/drive/MyDrive/Colab Notebooks/Projet 8/' + EXPERIMENT + '.keras')"],"metadata":{"id":"JBnAauhxvv59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loader = Dataloader(\n","    data_folder=X_test_dir,\n","    batch_size=1,           # Pour la démo, plus lisible\n","    transform=val_transform,\n","    shuffle=False\n",")"],"metadata":{"id":"AQf4qByBv6pq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images, masks = test_loader[1]\n","image = images[0]\n","true_mask = masks[0]"],"metadata":{"id":"2Z9wZ4rjv9SD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# on doit rajouter une dimension à l'image au début pour qu'elle ait la bonne forme pour entrer dans le modèle (batch)\n","pred = model.predict(np.expand_dims(image, 0))\n","# on réduit le mask de one hot à une image\n","pred_mask = np.argmax(pred[0], axis=-1)\n","image_file = test_loader.indexes[1] + \"_leftImg8bit.png\"\n","original_image = np.array(Image.open(image_file))\n","original_shape = original_image.shape[:2][::-1] # (width, height)\n","pred_mask_resized = np.array(\n","    Image.fromarray(pred_mask.astype(np.uint8)).resize(\n","        original_shape, resample=Image.NEAREST\n","    )\n",")\n","\n","# Affichage\n","fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n","axs[0].imshow(original_image)\n","axs[0].set_title(\"Image d'origine\")\n","axs[0].axis(\"off\")\n","axs[1].imshow(pred_mask_resized, cmap=\"tab20\", vmin=0, vmax=7)\n","axs[1].set_title(\"Mask prédit (taille d'origine)\")\n","axs[1].axis(\"off\")\n","axs[2].imshow(image)\n","axs[2].set_title(\"Image prétraitée (entrée modèle)\")\n","axs[2].axis(\"off\")\n","plt.tight_layout()\n","plt.tight_layout()\n","plt.savefig(os.path.join(imgPrezPath, \"trio_linknet_pred.svg\"),format=\"svg\",bbox_inches=\"tight\",pad_inches=0.1,)"],"metadata":{"id":"0iCR8awwv__D"},"execution_count":null,"outputs":[]}]}