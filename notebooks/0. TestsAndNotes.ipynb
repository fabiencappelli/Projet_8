{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1WRhIZeB_awGEvYVmA1MAQvmZx8Gvjucl","authorship_tag":"ABX9TyN3LDcX7RD4thKMkg7UOUGZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hzsgUK9V-Gll"},"outputs":[],"source":["import os\n","\n","img_dir = \"/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit/train\"\n","mask_dir = \"/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_gtFine_trainvaltest/gtFine8/train\"\n","\n","pairs = []\n","for ville in os.listdir(img_dir):\n","    for img_file in os.listdir(os.path.join(img_dir, ville)):\n","        if img_file.endswith(\"_leftImg8bit.png\"):\n","            img_path = os.path.join(img_dir, ville, img_file)\n","            # Pour le mask : remplacer le suffixe\n","            mask_file = img_file.replace(\"_leftImg8bit.png\", \"_gtFine_labelIds.png\")\n","            mask_path = os.path.join(mask_dir, ville, mask_file)\n","            if os.path.exists(mask_path):\n","                pairs.append((img_path, mask_path))\n","            else:\n","                print(f\"WARNING: mask not found for {img_path}\")\n","\n","print(f\"Nombre de paires trouvées : {len(pairs)}\")"]},{"cell_type":"code","source":["import os\n","\n","train_dir = \"/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit/train\"\n","val_dir = \"/content/drive/MyDrive/Colab Notebooks/Projet 8/P8_Cityscapes_leftImg8bit_trainvaltest/leftImg8bit/val\"\n","\n","nb_train = len([name for name in os.listdir(train_dir) if name.endswith('leftImg8bit.png')])\n","nb_val = len([name for name in os.listdir(val_dir) if name.endswith('leftImg8bit.png')])\n","total = nb_train + nb_val\n","\n","print(f\"nous avons {nb_train} images dans le train\")\n","print(f\"nous avons {nb_val} images dans le val\")\n","print(f\"Le val représente {round(100*nb_val/total,2)}% du total\")"],"metadata":{"id":"Ufb_z341izjS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import matplotlib.pyplot as plt"],"metadata":{"id":"TzHohkAg-eQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scroll_pairs(numero):\n","  img_path, mask_path = pairs[numero]\n","  img = Image.open(img_path)\n","  mask = Image.open(mask_path)\n","\n","  plt.figure(figsize=(16,8))\n","  plt.subplot(1,2,1)\n","  plt.title('Image RGB')\n","  plt.imshow(img)\n","  plt.axis('off')\n","  plt.subplot(1,2,2)\n","  plt.title('Mask 8 classes')\n","  plt.imshow(mask, cmap='nipy_spectral')\n","  plt.axis('off')\n","  plt.show()\n"],"metadata":{"id":"HgEiyddL_QA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scroll_pairs(0)"],"metadata":{"id":"EJ01pgZY_dnY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scroll_pairs(1000)"],"metadata":{"id":"K40z7L8b_q6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scroll_pairs(100)"],"metadata":{"id":"q7m9AwKPABgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"iAN3ufwuAxWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(pairs, columns=['img_path', 'mask_path'])"],"metadata":{"id":"x_i3eiG3AqPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"WONkr93AA014"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Redimensionner en divisant par 4\n","\n","on prend resize d'open cv même pour le mask mais attention à la méthode d'interpolation pour pas inventer de nouvelles catégories\n","\n","https://www.geeksforgeeks.org/image-processing-opencv-vs-pil/\n","\n","https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121\n","\n","Pour les masques de segmentation (annotations “labels”)\n","Il ne faut JAMAIS utiliser une interpolation “continue” (comme bilinear ou bicubic) sur un masque de labels :\n","→ Ces méthodes inventeraient des valeurs intermédiaires, donc des “fausses” classes, par interpolation mathématique (genre 2.7, 5.2, etc.).\n","\n","Il faut utiliser une interpolation “discrète” qui conserve les entiers des classes, donc :\n","\n","cv2.INTER_NEAREST (nearest neighbor, “plus proche voisin”)\n","→ Cela garantit que chaque pixel du mask agrandi/réduit garde exactement la valeur d’une classe existante, sans mélange.\n","\n","Pour les images RGB (photos)\n","Tu peux utiliser cv2.INTER_LINEAR (bilinear) ou cv2.INTER_AREA (pour réduire), ou même cv2.INTER_CUBIC (pour agrandir), car les valeurs de pixels sont continues et peuvent être “moyennées”.\n","\n","Non, ce n’est pas problématique, c’est même la seule bonne pratique en vision par ordinateur pour la segmentation sémantique.\n","\n","Pourquoi utiliser une interpolation différente pour l’image et pour le mask ?\n","Les images RGB :\n","→ Ce sont des données “visuelles continues”.\n","→ On peut “moyenner” ou “interpoler” les couleurs entre deux pixels sans aucun problème (c’est ce qui rend l’image agréable à l’œil même agrandie ou réduite).\n","\n","Les masques de segmentation :\n","→ Ce sont des “données discrètes”, c’est-à-dire des entiers qui codent une catégorie :\n","0 = route, 1 = trottoir, 2 = voiture, etc.\n","→ Si tu “interpolais” (ex: bilinear), tu obtiendrais des pixels ayant des valeurs impossibles (3.5, 7.2...), donc des classes qui n’existent pas : c’est une erreur fondamentale !"],"metadata":{"id":"q5fdTXmIDU6h"}},{"cell_type":"markdown","source":["Voir le github qubvel segmentation (examples)\n","Le but du data generator c'est de faire des batches"],"metadata":{"id":"XWliuqR4EQuZ"}},{"cell_type":"markdown","source":["data augmentation : quand c de la transformation géométrique il faut faire pareil sur le mask"],"metadata":{"id":"GmT4CD2hE5sv"}}]}